From 0248be7347e640d3fec491c45703b4206d27e192 Mon Sep 17 00:00:00 2001
From: caojingyi <caojingyi@noreply.gitcode.com>
Date: Thu, 20 Nov 2025 19:11:20 +0800
Subject: [PATCH] Update vllm_ascend: dummy_run load balance
Implement load balance during `dummy_run`, expand KV Cache capacity and optimize the memory utilization.

---
 rl_train/qwen3/vllm_ascend/torchair/ops/torchair_fused_moe.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/rl_train/qwen3/vllm_ascend/torchair/ops/torchair_fused_moe.py b/rl_train/qwen3/vllm_ascend/torchair/ops/torchair_fused_moe.py
index 8b78af5..a58b281 100644
--- a/rl_train/qwen3/vllm_ascend/torchair/ops/torchair_fused_moe.py
+++ b/rl_train/qwen3/vllm_ascend/torchair/ops/torchair_fused_moe.py
@@ -934,7 +934,7 @@ class TorchairAscendUnquantizedFusedMoEMethod(UnquantizedFusedMoEMethod):
         # to avoid accumulating too much tokens on a single rank.
         # currently it is only activated when doing profile runs.
         if enable_force_load_balance and not self.use_aclgraph:
-            topk_ids = torch.randint_like(topk_ids, 0, global_num_experts)
+            topk_ids = (torch.arange(topk_ids.numel(), device=topk_ids.device) % global_num_experts).to(torch.int32).reshape(topk_ids.shape)
 
         fused_moe_state = get_forward_context().fused_moe_state
         if self.enable_shared_expert_dp and fused_moe_state == FusedMoEState.MC2:
-- 
2.50.1.windows.1

